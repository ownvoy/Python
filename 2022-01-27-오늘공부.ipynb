{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data Frame\n",
    "\n",
    "### Insepecing Data\n",
    "\n",
    "처음 Data Frame을 받았을 떄 어떻게 생겨먹었는지 궁금할 수 있다. 다음 매소드를 통해 이를 확인 할 수 있다.  \n",
    "아 근데 일단 데이터를 불러오도록 하겠다.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "homelessness = pd.read_csv('homelessness.csv', index_col = 0)\n",
    "sales = pd.read_csv(\"sales_subset.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `.head()`: 처음 5개의 row를 보여준다.  \n",
    "- `.info()`: column, data types, missing value 숫자들에 대한 정보를 보여준다.  \n",
    "- `.shape()`: row 와 column의 숫자를 알려준다.  \n",
    "- `.describe()`: column에 대한 짤막한 정보를 알려준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               region       state  individuals  family_members  state_pop\n",
      "0  East South Central     Alabama       2570.0           864.0    4887681\n",
      "1             Pacific      Alaska       1434.0           582.0     735139\n",
      "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
      "3  West South Central    Arkansas       2280.0           432.0    3009733\n",
      "4             Pacific  California     109008.0         20964.0   39461588\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   region          51 non-null     object \n",
      " 1   state           51 non-null     object \n",
      " 2   individuals     51 non-null     float64\n",
      " 3   family_members  51 non-null     float64\n",
      " 4   state_pop       51 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 2.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 5)\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         individuals  family_members     state_pop\n",
      "count      51.000000       51.000000  5.100000e+01\n",
      "mean     7225.784314     3504.882353  6.405637e+06\n",
      "std     15991.025083     7805.411811  7.327258e+06\n",
      "min       434.000000       75.000000  5.776010e+05\n",
      "25%      1446.500000      592.000000  1.777414e+06\n",
      "50%      3082.000000     1482.000000  4.461153e+06\n",
      "75%      6781.500000     3196.000000  7.340946e+06\n",
      "max    109008.000000    52070.000000  3.946159e+07\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같은 매소드를 통해 부분들을 더 잘 이해할 수 있다.  \n",
    "- `.value()`: 2D NumPy array의 value\n",
    "- `.column()`: column name을 보여준다.(an index of column)  \n",
    "- `.index()`: row name이나 row nummber을 보여준다. (an index of row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['East South Central' 'Alabama' 2570.0 864.0 4887681]\n",
      " ['Pacific' 'Alaska' 1434.0 582.0 735139]\n",
      " ['Mountain' 'Arizona' 7259.0 2606.0 7158024]\n",
      " ['West South Central' 'Arkansas' 2280.0 432.0 3009733]\n",
      " ['Pacific' 'California' 109008.0 20964.0 39461588]\n",
      " ['Mountain' 'Colorado' 7607.0 3250.0 5691287]\n",
      " ['New England' 'Connecticut' 2280.0 1696.0 3571520]\n",
      " ['South Atlantic' 'Delaware' 708.0 374.0 965479]\n",
      " ['South Atlantic' 'District of Columbia' 3770.0 3134.0 701547]\n",
      " ['South Atlantic' 'Florida' 21443.0 9587.0 21244317]\n",
      " ['South Atlantic' 'Georgia' 6943.0 2556.0 10511131]\n",
      " ['Pacific' 'Hawaii' 4131.0 2399.0 1420593]\n",
      " ['Mountain' 'Idaho' 1297.0 715.0 1750536]\n",
      " ['East North Central' 'Illinois' 6752.0 3891.0 12723071]\n",
      " ['East North Central' 'Indiana' 3776.0 1482.0 6695497]\n",
      " ['West North Central' 'Iowa' 1711.0 1038.0 3148618]\n",
      " ['West North Central' 'Kansas' 1443.0 773.0 2911359]\n",
      " ['East South Central' 'Kentucky' 2735.0 953.0 4461153]\n",
      " ['West South Central' 'Louisiana' 2540.0 519.0 4659690]\n",
      " ['New England' 'Maine' 1450.0 1066.0 1339057]\n",
      " ['South Atlantic' 'Maryland' 4914.0 2230.0 6035802]\n",
      " ['New England' 'Massachusetts' 6811.0 13257.0 6882635]\n",
      " ['East North Central' 'Michigan' 5209.0 3142.0 9984072]\n",
      " ['West North Central' 'Minnesota' 3993.0 3250.0 5606249]\n",
      " ['East South Central' 'Mississippi' 1024.0 328.0 2981020]\n",
      " ['West North Central' 'Missouri' 3776.0 2107.0 6121623]\n",
      " ['Mountain' 'Montana' 983.0 422.0 1060665]\n",
      " ['West North Central' 'Nebraska' 1745.0 676.0 1925614]\n",
      " ['Mountain' 'Nevada' 7058.0 486.0 3027341]\n",
      " ['New England' 'New Hampshire' 835.0 615.0 1353465]\n",
      " ['Mid-Atlantic' 'New Jersey' 6048.0 3350.0 8886025]\n",
      " ['Mountain' 'New Mexico' 1949.0 602.0 2092741]\n",
      " ['Mid-Atlantic' 'New York' 39827.0 52070.0 19530351]\n",
      " ['South Atlantic' 'North Carolina' 6451.0 2817.0 10381615]\n",
      " ['West North Central' 'North Dakota' 467.0 75.0 758080]\n",
      " ['East North Central' 'Ohio' 6929.0 3320.0 11676341]\n",
      " ['West South Central' 'Oklahoma' 2823.0 1048.0 3940235]\n",
      " ['Pacific' 'Oregon' 11139.0 3337.0 4181886]\n",
      " ['Mid-Atlantic' 'Pennsylvania' 8163.0 5349.0 12800922]\n",
      " ['New England' 'Rhode Island' 747.0 354.0 1058287]\n",
      " ['South Atlantic' 'South Carolina' 3082.0 851.0 5084156]\n",
      " ['West North Central' 'South Dakota' 836.0 323.0 878698]\n",
      " ['East South Central' 'Tennessee' 6139.0 1744.0 6771631]\n",
      " ['West South Central' 'Texas' 19199.0 6111.0 28628666]\n",
      " ['Mountain' 'Utah' 1904.0 972.0 3153550]\n",
      " ['New England' 'Vermont' 780.0 511.0 624358]\n",
      " ['South Atlantic' 'Virginia' 3928.0 2047.0 8501286]\n",
      " ['Pacific' 'Washington' 16424.0 5880.0 7523869]\n",
      " ['South Atlantic' 'West Virginia' 1021.0 222.0 1804291]\n",
      " ['East North Central' 'Wisconsin' 2740.0 2167.0 5807406]\n",
      " ['Mountain' 'Wyoming' 434.0 205.0 577601]]\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "            50],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(homelessness.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sorting and subsetting\n",
    "\n",
    "row의 순서를 바꾸고 싶다면, `.sort_values()`를 통해 바꿀 수 있다. 안에 collumn name을 넣으면 된다.  \n",
    "예를 들어 `homelessness.sort_values('individuals')`를 하면 작은 수에서 큰 수로 정렬 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region         state  individuals  family_members  state_pop\n",
      "50            Mountain       Wyoming        434.0           205.0     577601\n",
      "34  West North Central  North Dakota        467.0            75.0     758080\n",
      "7       South Atlantic      Delaware        708.0           374.0     965479\n",
      "39         New England  Rhode Island        747.0           354.0    1058287\n",
      "45         New England       Vermont        780.0           511.0     624358\n"
     ]
    }
   ],
   "source": [
    "homelessness_ind = homelessness.sort_values('individuals')\n",
    "print(homelessness_ind.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "큰 수 부터 하고 정렬하고 싶다면 `ascending = False`를 넣어 주면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region          state  individuals  family_members  state_pop\n",
      "32        Mid-Atlantic       New York      39827.0         52070.0   19530351\n",
      "4              Pacific     California     109008.0         20964.0   39461588\n",
      "21         New England  Massachusetts       6811.0         13257.0    6882635\n",
      "9       South Atlantic        Florida      21443.0          9587.0   21244317\n",
      "43  West South Central          Texas      19199.0          6111.0   28628666\n"
     ]
    }
   ],
   "source": [
    "homelessness_fam = homelessness.sort_values(\"family_members\",ascending = False)\n",
    "print(homelessness_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column을 두개 선택해서 정렬 할 수 도 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region      state  individuals  family_members  state_pop\n",
      "13  East North Central   Illinois       6752.0          3891.0   12723071\n",
      "35  East North Central       Ohio       6929.0          3320.0   11676341\n",
      "22  East North Central   Michigan       5209.0          3142.0    9984072\n",
      "49  East North Central  Wisconsin       2740.0          2167.0    5807406\n",
      "14  East North Central    Indiana       3776.0          1482.0    6695497\n"
     ]
    }
   ],
   "source": [
    "homelessness_reg_fam = homelessness.sort_values([\"region\",\"family_members\"],ascending=[True,False])\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsetting column 를 하는 방법은 간단하다. `[]`를 이용하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2570.0\n",
      "1      1434.0\n",
      "2      7259.0\n",
      "3      2280.0\n",
      "4    109008.0\n",
      "Name: individuals, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "individuals = homelessness[\"individuals\"]\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   individuals       state\n",
      "0       2570.0     Alabama\n",
      "1       1434.0      Alaska\n",
      "2       7259.0     Arizona\n",
      "3       2280.0    Arkansas\n",
      "4     109008.0  California\n"
     ]
    }
   ],
   "source": [
    "ind_state = homelessness[[\"individuals\",\"state\"]]\n",
    "print(ind_state.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subsetting row 를 하는 방법은 많이 있지만 그중 가장 보편적인 것은 `True` 와 `False`를 통해 걸러 내는 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region이 Mountain인 row를 선택해 보도록 하자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "5   Mountain    Colorado       7607.0          3250.0    5691287\n",
      "12  Mountain       Idaho       1297.0           715.0    1750536\n",
      "26  Mountain     Montana        983.0           422.0    1060665\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "31  Mountain  New Mexico       1949.0           602.0    2092741\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n",
      "50  Mountain     Wyoming        434.0           205.0     577601\n"
     ]
    }
   ],
   "source": [
    "mountain_reg = homelessness[homelessness[\"region\"]==\"Mountain\"]\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "family member가 1000 이하이고 region Pacific인 row를 찾아보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region   state  individuals  family_members  state_pop\n",
      "1  Pacific  Alaska       1434.0           582.0     735139\n"
     ]
    }
   ],
   "source": [
    "fam_lt_1k_pac= homelessness[(homelessness[\"family_members\"]<1000) & (homelessness[\"region\"]== \"Pacific\")]\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조건이 두 개가 붙으면 `&` 통해 연결 할 수 있으며, `()`를 써주어야 한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`or`를 통해 연결하고 싶으면 간단하게 `|`를 쓸 수도 있다. region 이 South Atlantic이거나 Mid Atlantic인 row를 찾아 보자.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            region                 state  individuals  family_members  \\\n",
      "7   South Atlantic              Delaware        708.0           374.0   \n",
      "8   South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9   South Atlantic               Florida      21443.0          9587.0   \n",
      "10  South Atlantic               Georgia       6943.0          2556.0   \n",
      "20  South Atlantic              Maryland       4914.0          2230.0   \n",
      "30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
      "32    Mid-Atlantic              New York      39827.0         52070.0   \n",
      "33  South Atlantic        North Carolina       6451.0          2817.0   \n",
      "38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
      "40  South Atlantic        South Carolina       3082.0           851.0   \n",
      "46  South Atlantic              Virginia       3928.0          2047.0   \n",
      "48  South Atlantic         West Virginia       1021.0           222.0   \n",
      "\n",
      "    state_pop  \n",
      "7      965479  \n",
      "8      701547  \n",
      "9    21244317  \n",
      "10   10511131  \n",
      "20    6035802  \n",
      "30    8886025  \n",
      "32   19530351  \n",
      "33   10381615  \n",
      "38   12800922  \n",
      "40    5084156  \n",
      "46    8501286  \n",
      "48    1804291  \n"
     ]
    }
   ],
   "source": [
    "south_mid_atlantic = homelessness[(homelessness[\"region\"]==\"South Atlantic\")|(homelessness[\"region\"]==\"Mid-Atlantic\")]\n",
    "print(south_mid_atlantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하면 너무 길어 질 수 있어서 `.isin()`를 통해도 가능하다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "4    Pacific  California     109008.0         20964.0   39461588\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n"
     ]
    }
   ],
   "source": [
    "\n",
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
    "\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 column을 추가하는 것은 간단하다. `[]`안에 column name을 써주고 값을 넣어주면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               region       state  individuals  family_members  state_pop  \\\n",
      "0  East South Central     Alabama       2570.0           864.0    4887681   \n",
      "1             Pacific      Alaska       1434.0           582.0     735139   \n",
      "2            Mountain     Arizona       7259.0          2606.0    7158024   \n",
      "3  West South Central    Arkansas       2280.0           432.0    3009733   \n",
      "4             Pacific  California     109008.0         20964.0   39461588   \n",
      "\n",
      "      total  p_individuals  \n",
      "0    3434.0       0.748398  \n",
      "1    2016.0       0.711310  \n",
      "2    9865.0       0.735834  \n",
      "3    2712.0       0.840708  \n",
      "4  129972.0       0.838704  \n"
     ]
    }
   ],
   "source": [
    "homelessness[\"total\"]= homelessness[\"individuals\"]+homelessness[\"family_members\"]\n",
    "homelessness[\"p_individuals\"] = homelessness[\"individuals\"]/homelessness[\"total\"]\n",
    "print(homelessness.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregaiting Dataframe\n",
    "\n",
    "summary statistics은 mean, median, minimum, maximum, and standard deviation 같은 것을 의미한다. 이를 봐 보도록 하자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843.950148505668\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"weekly_sales\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.max()` , `.min()`를 통해 최대치와 최소치도 알 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.agg()`를 통해 Data Frame에 custom function을 적용할 수도 있다.  \n",
    "\n",
    "iqr 함수를 만들어 적용해 보도록 하자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "print(sales[\"temperature_c\"].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 행에도 적용할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수 2개를 적용할 수 도 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas 에는 cumulative statistics도 있다. `.cumsum()`은 row의 합들이 쌓여가며, `.cummax()`는 row에서 큰 값들이 적힌다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0      2010-02-05      24924.50      2.492450e+04       24924.50\n",
      "6437   2010-02-05      38597.52      6.352202e+04       38597.52\n",
      "1249   2010-02-05       3840.21      6.736223e+04       38597.52\n",
      "6449   2010-02-05      17590.59      8.495282e+04       38597.52\n",
      "6461   2010-02-05       4929.87      8.988269e+04       38597.52\n",
      "...           ...           ...               ...            ...\n",
      "3592   2012-10-05        440.00      2.568932e+08      293966.05\n",
      "8108   2012-10-05        660.00      2.568938e+08      293966.05\n",
      "10773  2012-10-05        915.00      2.568947e+08      293966.05\n",
      "6257   2012-10-12          3.00      2.568947e+08      293966.05\n",
      "3384   2012-10-26        -21.63      2.568947e+08      293966.05\n",
      "\n",
      "[10774 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_1_1 = sales.sort_values(\"date\")\n",
    "\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "sales_1_1[\"cum_max_sales\"]=sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 numeric variable을 다루는 방법을 배웠다면, 이제는 categorical variable을 다루는 방법을 공부할 것이다.\n",
    "\n",
    "`sales`의 중복된 값을 제거해보도록 하자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      store type  department        date  weekly_sales  is_holiday  \\\n",
      "0         1    A           1  2010-02-05      24924.50       False   \n",
      "901       2    A           1  2010-02-05      35034.06       False   \n",
      "1798      4    A           1  2010-02-05      38724.42       False   \n",
      "2699      6    A           1  2010-02-05      25619.00       False   \n",
      "3593     10    B           1  2010-02-05      40212.84       False   \n",
      "\n",
      "      temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          5.727778              0.679451         8.106  \n",
      "901        4.550000              0.679451         8.324  \n",
      "1798       6.533333              0.686319         8.623  \n",
      "2699       4.683333              0.679451         7.259  \n",
      "3593      12.411111              0.782478         9.765  \n"
     ]
    }
   ],
   "source": [
    "store_types = sales.drop_duplicates([\"store\",\"type\"])\n",
    "print(store_types.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store type  department        date  weekly_sales  is_holiday  \\\n",
      "0       1    A           1  2010-02-05      24924.50       False   \n",
      "12      1    A           2  2010-02-05      50605.27       False   \n",
      "24      1    A           3  2010-02-05      13740.12       False   \n",
      "36      1    A           4  2010-02-05      39954.04       False   \n",
      "48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n"
     ]
    }
   ],
   "source": [
    "store_depts = sales.drop_duplicates([\"store\",\"department\"])\n",
    "print(store_depts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`is_holiday`가 `True`인 row 중에서 `date`가 중복인 row를 drop 해보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498     2010-09-10\n",
      "691     2011-11-25\n",
      "2315    2010-02-12\n",
      "6735    2012-09-07\n",
      "6810    2010-12-31\n",
      "6815    2012-02-10\n",
      "6820    2011-09-09\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "holiday_dates = sales[sales[\"is_holiday\"]== True].drop_duplicates(\"date\")\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.value_counts`를 통해 categorical value를 셀 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`normalize`는 count를 비율로 바꿔 준다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sort = True`를 하면 count가 큰 거부터 정렬된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data 를 group 지어서 보고 싶을 수도 있을 것이다. 다음은 타입별로 weekly_sales의 합이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9097747 0.0902253 0.       ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_all = sales[\"weekly_sales\"].sum()\n",
    "\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런식으로 sales_A, sales_B 하는 방식은 약간 피곤하다. 이를 간단하게 하는 것으로는 `.groupby()`가 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "sales_propn_by_type = sales_by_type/sum(sales_by_type)\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러가지 함수를 적용하고 싶다면 `.agg()`를 사용하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amin       amax          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n"
     ]
    }
   ],
   "source": [
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min,np.max,np.mean,np.median])\n",
    "print(sales_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type에 대해서 두가지 variable을 aggregate할 수도 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "             amin   amax      mean median                 amin      amax   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wj527\\AppData\\Local\\Temp/ipykernel_42672/196932519.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  unemp_fuel_stats = sales.groupby(\"type\")[\"unemployment\",\"fuel_price_usd_per_l\"].agg([np.min,np.max,np.mean,np.median])\n"
     ]
    }
   ],
   "source": [
    "unemp_fuel_stats = sales.groupby(\"type\")[\"unemployment\",\"fuel_price_usd_per_l\"].agg([np.min,np.max,np.mean,np.median])\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pivot table은 grouped summary statistics을 계산하는 또 다른 방법이다. 위와 같은 작업을 `.pivot_table()`를 통해 똑같이 할 수 있다. \"values\" argument 은 summarize하고 싶은 column 이며, \"index\" argument는 group by 하고 싶은 column이다. pivot_table은 default로 mean을 value로 취한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "mean_sales_by_type = sales.pivot_table(values=\"weekly_sales\",index=\"type\")\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean 과 median을 둘 다 pivot 하려면 `aggfunc`을 사용하면 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "mean_med_sales_by_type = sales.pivot_table(values=\"weekly_sales\",index= \"type\",aggfunc=[np.mean, np.median])\n",
    "\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column을 설정함으로써 two variable을 group by 할 수 도 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday         False       True\n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_sales_by_type_holiday = sales.pivot_table(values=\"weekly_sales\",index=\"type\",columns=\"is_holiday\")\n",
    "\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department            1              2             3             4   \\\n",
      "type                                                                  \n",
      "A           30961.725379   67600.158788  17160.002955  44285.399091   \n",
      "B           44050.626667  112958.526667  30580.655000  51219.654167   \n",
      "\n",
      "department            5             6             7             8   \\\n",
      "type                                                                 \n",
      "A           34821.011364   7136.292652  38454.336818  48583.475303   \n",
      "B           63236.875000  10717.297500  52909.653333  90733.753333   \n",
      "\n",
      "department            9             10  ...            90            91  \\\n",
      "type                                    ...                               \n",
      "A           30120.449924  30930.456364  ...  85776.905909  70423.165227   \n",
      "B           66679.301667  48595.126667  ...  14780.210000  13199.602500   \n",
      "\n",
      "department             92            93            94             95  \\\n",
      "type                                                                   \n",
      "A           139722.204773  53413.633939  60081.155303  123933.787121   \n",
      "B            50859.278333   1466.274167    161.445833   77082.102500   \n",
      "\n",
      "department            96            97            98          99  \n",
      "type                                                              \n",
      "A           21367.042857  28471.266970  12875.423182  379.123659  \n",
      "B            9528.538333   5828.873333    217.428333         NaN  \n",
      "\n",
      "[2 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sales.pivot_table(values=\"weekly_sales\",index=\"type\",columns = \"department\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missingi value로 `NaN`이 있는 것을 확인할 수 있다. `fill_value=0`을 통해 이를 0으로 바꿀 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department            1              2             3             4   \\\n",
      "type                                                                  \n",
      "A           30961.725379   67600.158788  17160.002955  44285.399091   \n",
      "B           44050.626667  112958.526667  30580.655000  51219.654167   \n",
      "\n",
      "department            5             6             7             8   \\\n",
      "type                                                                 \n",
      "A           34821.011364   7136.292652  38454.336818  48583.475303   \n",
      "B           63236.875000  10717.297500  52909.653333  90733.753333   \n",
      "\n",
      "department            9             10  ...            90            91  \\\n",
      "type                                    ...                               \n",
      "A           30120.449924  30930.456364  ...  85776.905909  70423.165227   \n",
      "B           66679.301667  48595.126667  ...  14780.210000  13199.602500   \n",
      "\n",
      "department             92            93            94             95  \\\n",
      "type                                                                   \n",
      "A           139722.204773  53413.633939  60081.155303  123933.787121   \n",
      "B            50859.278333   1466.274167    161.445833   77082.102500   \n",
      "\n",
      "department            96            97            98          99  \n",
      "type                                                              \n",
      "A           21367.042857  28471.266970  12875.423182  379.123659  \n",
      "B            9528.538333   5828.873333    217.428333    0.000000  \n",
      "\n",
      "[2 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sales.pivot_table(values=\"weekly_sales\",index=\"type\",columns = \"department\",fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`margin= True`를 설정하면 row와 column의 합을 제시한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type                   A              B           All\n",
      "department                                           \n",
      "1           30961.725379   44050.626667  32052.467153\n",
      "2           67600.158788  112958.526667  71380.022778\n",
      "3           17160.002955   30580.655000  18278.390625\n",
      "4           44285.399091   51219.654167  44863.253681\n",
      "5           34821.011364   63236.875000  37189.000000\n",
      "...                  ...            ...           ...\n",
      "96          21367.042857    9528.538333  20337.607681\n",
      "97          28471.266970    5828.873333  26584.400833\n",
      "98          12875.423182     217.428333  11820.590278\n",
      "99            379.123659       0.000000    379.123659\n",
      "All         23674.667242   25696.678370  23843.950149\n",
      "\n",
      "[81 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"department\", columns=\"type\",fill_value=0, margins= True))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
